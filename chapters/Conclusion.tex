\chapter{Conclusions}\label{ch:conclusion}

The EJs search looked for pair production of the scalar mediator at the LHC, which yields events with two SM jets and two EJs at leading order.
The results are interpreted using two dark sector models with different flavor structures, referred to as "Flavored-aligned" and "Unflavored".
For the unflavored model, $m_{X_{DK}} <$  1950 GeV are excluded for $c\tau_{\pi_{DK}} \approx$ 100mm and $m_{\pi_{DK}}=$~10~GeV. In the flavor-aligned scenario we exclude $m_{X_{DK}} <$  1850 GeV at $c\tau^{max}_{\pi_{DK}} \approx$ 500mm for $m_{\pi_{DK}}$= 10GeV.
The unflavored results surpass a previous search for emerging jets by setting the most stringent mediator mass exclusion limits to date, while the flavor-aligned results provide the first direct mediator mass exclusion limits.

% This result surpasses the previous search for emerging jets in the unflavored scenario, and increases the limit of the dark mediator particle by $\approx$ 500GeV
The work described here shows my contributions to the EJs analysis in the study of trigger efficiencies and how it is an integral part of recording the appropriate data with high quality and sufficient statistics.
The efficiency curves were used to determine the energy thresholds that the analysis would use to mitigate the turn-on effects of the triggers.
Any uncertainties or deviations were properly studied and applied to simulation data to ensure that the signal was well modeled.
This analysis is now public on \cite{CMS:2024gxp} and has been sent for publication in the Journal for High-Energy Physics (JHEP).


My work also contributed to the very first design of tools that strives to enable a machine learning-based DQM process for the CMS Tracker to meet challenges at the HL-LHC.
A Run ranking system to grade reference runs was developed and tested on the certification data from CMS.
This system would assist DQM shift personnel in the process of selecting new reference runs and possibly begin the automation of this procedure.
Finally, my work on the development and automation for the data ingestion of the new MLP is a first step in building a robust data exploration tool, promoting the mission of an ML-based data certification workflow for efficient DQM.
