\chapter{Introduction}

The Standard Model (SM) of particle physics~\cite{What_is_SM} has been very successful in explaining many parts of the universe as it exists now. However, there are several unanswered questions for which SM is insufficient, for example, the nature of Dark Matter (DM) and Dark Energy, matter-antimatter asymmetry, unique mass of Higgs Boson, neutrino mass problem, and many more. The Large Hadron Collider (LHC) \cite{What_is_LHC} at CERN\cite{What_is_CERN} is the most powerful accelerator in the world with the ability to look into what is called Beyond the Standard Model Physics (BSM) and might help answer these questions. It will soon be upgraded to what is called the High-Luminosity LHC (HL-LHC)~\cite{hl-lhc} and will provide orders of magnitudes more collisions and data, along with new challenges. There are several experimental apparatus that populate the 27~\unit{km} circumference of the LHC that are designed to take, process, and analyze data from the proton-proton collisions at the center-of-mass energy of up to 14~\unit{TeV}.
One of these experiments is called the Compact Muon Solenoid (CMS) \cite{CMS_detector} and is one of the most sophisticated instruments built by humans. The CMS experimental collaboration is comprised of over 200 universities and institutes from over 50 countries around the globe. In the United States, there are about 50 institutions in the CMS experiment where Fermilab is the host institution for these. The LHC Physics Center (LPC) at Fermilab provides its users with state-of-the-art computing facilities, a remote CMS operations center, and physics and detector expertise.
The data collected from the CMS experiment is used for the work of this thesis. The LPC at Fermilab provided the facilities and tools to carry out the work described.

CERN was founded in 1954 and is located at the Franco-Swiss border near Geneva. At CERN, physicists and engineers are probing the fundamental structure of the universe. They use the world's largest and most complex scientific instruments to study the basic constituents of matter --- the fundamental particles.
The instruments used at CERN are purpose-built particle accelerators (LHC) and detectors like CMS, ATLAS \cite{What_is_ATLAS}, LHCb \cite{What_is_LHCb}, and ALICE \cite{What_is_ALICE}. Accelerators boost beams of particles to high energies before the beams are made to collide with each other or with stationary targets. Specifically, at the LHC proton-proton beams are accelerated to up to 14~TeV and collide at few points around the LHC tunnel, like Point 5 (P5) which is the location of CMS experiment.
Detectors observe and record the results of these collisions.
The LHC accelerates the protons almost up to the speed of light.
The proton collisions give physicists clues about the state of the universe just after the Big Bang and provide insights into the fundamental laws of nature. There are nine\footnote{\url{https://home.cern/science/experiments}} experiments at the LHC that analyze particles produced by proton collisions.
The biggest of these experiments, ATLAS and CMS, are general-purpose detectors designed to study the fundamental nature of matter and fundamental forces and to look for new physics or evidence of particles that are beyond the Standard Model.
Having two independently designed detectors is vital for cross-confirmation of any discoveries. The other two major experiments, ALICE and LHCb, respectively, study a state of matter (Quark-Gluon Plasma) that was present just moments after the Big Bang with a preponderance of matter over antimatter. Each experiment does important research that is key to understanding the universe that surrounds and makes us.

This thesis work focuses on studies performed towards a search for ``Emerging Jets'' (EJs) produced in proton-proton collisions at a center-of-mass energy of 13 TeV. The data collected by the CMS experiment corresponds to an integrated luminosity of 138 \unit{fb^{-1}}. This search examines a hypothetical dark quantum chromodynamics (QCD) sector that couples to the SM matter through a scalar mediator. The scalar mediator decays into an SM quark and a DM quark. As the DM quark showers and hadronizes, it produces long-lived dark mesons that subsequently decay into SM particles, resulting in a jet, known as an emerging jet, with multiple displaced vertices. We looked for pair production of the scalar mediator which yields events with two SM jets and two emerging jets at leading order. This analysis \cite{CMS:2024gxp} excluded mediator masses up to 1950 (1850) GeV for an unflavored (flavor-aligned) dark QCD model. The unflavored results surpass a previous search for emerging jets \cite{sirunyan2019search} by setting the most stringent mediator mass exclusion limits to date, while the flavor-aligned results provide the first direct mediator mass exclusion limits to date.
This was a multi-institution effort with physicists from the University of Puerto Rico-Mayag√ºez, Colorado University-Boulder, University of Maryland, Panjab University, and Fermilab, and took over two years to complete. Within this analysis team, I worked on trigger studies and determined the scale factors that adjust for any inadequate modeling of Monte Carlo signal simulation data due to trigger turn-on effects. This analysis is now public on \cite{CMS:2024gxp} and has been sent for publication in the Journal for High-Energy Physics (JHEP).

The collision data collected by the CMS experiment is of very high quality and to ensure this, a process called Data Quality Monitoring (DQM) \cite{DeGuioDQM} is in place. This is a challenging process because it requires manual monitoring of the status of thousands of detector elements and their corresponding data.
As the size of the data and luminosity increases, it is essential that DQM transitions to an automated mode wherein the key is Machine Learning. The innermost component of the CMS detector, called the Tracker comprises of millions of readout channels and makes the machine learning task even more challenging. The other part of the work of this thesis describes developing tools directed at automating the DQM process with ML-enabled workflows \cite{Wachirapusitan_2023}. These provide a mechanism to filter, evaluate, and certify the quality of data collected in the CMS experiment.

This thesis is divided into the following chapters.
\Cref{ch:CMS} presents a basic description of the CMS Detector.
\Cref{ch:emj} presents a description and background on the Emerging Jets theory and analysis.
\Cref{ch:DQM} gives a brief description of what is Data Quality Monitoring (DQM) and its importance for CMS, as well as describe the Machine Learning tasks developed for it.
\Cref{ch:conclusion} summarizes the analysis results and ongoing DQM efforts.



The thesis work has been presented at conferences.
\cite{user-meeting2023,prism2022,DPF,prism2019}
My research experience also led me to contribute to software trainings in HEP, broader impacts and outreach.
These are described in the \hyperlink{appendix}{Appendix}

% \cite{CUpathways,ml-hackathon,newpersp2018,physcon,prism2019,UMCERN2018,newpersp2023,DPF,prism,pyhep22,root-workshop,uprm-fair,user-meeting2023}
